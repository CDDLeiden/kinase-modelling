{
    "hidden_size" : 1700, 
    "depth" : 4, 
    "dropout" : 0.13,
    "ffn_num_layers" : 3,
    "activation" : "PReLU",
    "max_lr" : 0.0005,
    "epochs" : 50,
    "bias" : ""
}